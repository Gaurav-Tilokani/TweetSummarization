{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-04T04:26:17.289851Z","iopub.execute_input":"2023-05-04T04:26:17.290793Z","iopub.status.idle":"2023-05-04T04:26:17.362038Z","shell.execute_reply.started":"2023-05-04T04:26:17.290747Z","shell.execute_reply":"2023-05-04T04:26:17.360937Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tweets/valid.csv\n/kaggle/input/tweets/train.csv\n/kaggle/input/tweets/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Installing and importing needed libraries**\n* tweet-preprocessor for preprocessing of tweets: it handles URLs, Mentions, Reserved words (eg, RT, FAV, etc), Emojis\n* Using GPU to run code","metadata":{}},{"cell_type":"code","source":"!pip install tweet-preprocessor\nimport preprocessor as p\nimport numpy as np\nimport pandas as pd\nfrom transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers.optimization import Adafactor, AdafactorSchedule\nimport torch\nimport huggingface_hub\nimport gc\nfrom torch import nn \nimport nltk\nimport datasets\n!pip install rouge_score\n\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:26:17.365365Z","iopub.execute_input":"2023-05-04T04:26:17.366525Z","iopub.status.idle":"2023-05-04T04:26:54.981780Z","shell.execute_reply.started":"2023-05-04T04:26:17.366486Z","shell.execute_reply":"2023-05-04T04:26:54.980450Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tweet-preprocessor\n  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\nInstalling collected packages: tweet-preprocessor\nSuccessfully installed tweet-preprocessor-0.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.21.6)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=4f298b7c117b740e54b72db4fcf2b621be52c671a81adfb9e90618a85d650c63\n  Stored in directory: /root/.cache/pip/wheels/8e/6b/70/59daa7c90a238610e34bac5916e001fe3d9bb0ec59c8cf5518\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"**Note : This dataset is generated with help of ChatGPT because there is no Dataset available for Tweets and their Summaries**\n\n**Loading Dataset**\n* train.csv -> Contains Training Data (1148 rows)\n* valid.csv -> Contains Validation Data (104 rows)\n* test.csv -> Contains Testing Data (101 rows)","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweets/train.csv')\nvalid = pd.read_csv('/kaggle/input/tweets/valid.csv')\ntest = pd.read_csv('/kaggle/input/tweets/test.csv')\nprint(len(train))\nprint(len(test))\nprint(len(valid))","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:26:54.983873Z","iopub.execute_input":"2023-05-04T04:26:54.985869Z","iopub.status.idle":"2023-05-04T04:26:55.032230Z","shell.execute_reply.started":"2023-05-04T04:26:54.985820Z","shell.execute_reply":"2023-05-04T04:26:55.031129Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"1148\n101\n104\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:26:55.035487Z","iopub.execute_input":"2023-05-04T04:26:55.035865Z","iopub.status.idle":"2023-05-04T04:26:55.055476Z","shell.execute_reply.started":"2023-05-04T04:26:55.035825Z","shell.execute_reply":"2023-05-04T04:26:55.054340Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              inputs  \\\n0  Artificial intelligence is transforming the he...   \n1  The future of transportation is electric. With...   \n2  Remote work is here to stay, and it's changing...   \n3  Blockchain technology is transforming the way ...   \n4  The global food system is facing unprecedented...   \n\n                                           summaries  \n0  AI is revolutionizing healthcare by improving ...  \n1  EVs are the future of transportation, and as w...  \n2  Remote work is changing the way we balance wor...  \n3  Blockchain is transforming business by enablin...  \n4  Building a sustainable and equitable food syst...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n      <th>summaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Artificial intelligence is transforming the he...</td>\n      <td>AI is revolutionizing healthcare by improving ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The future of transportation is electric. With...</td>\n      <td>EVs are the future of transportation, and as w...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Remote work is here to stay, and it's changing...</td>\n      <td>Remote work is changing the way we balance wor...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Blockchain technology is transforming the way ...</td>\n      <td>Blockchain is transforming business by enablin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The global food system is facing unprecedented...</td>\n      <td>Building a sustainable and equitable food syst...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(len(train)):\n    train['inputs'][i] = p.clean(train['inputs'][i])\n\nfor i in range(len(test)):\n    test['inputs'][i] = p.clean(test['inputs'][i])\n\nfor i in range(len(valid)):\n    train['inputs'][i] = p.clean(valid['inputs'][i])","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:26:55.057838Z","iopub.execute_input":"2023-05-04T04:26:55.058625Z","iopub.status.idle":"2023-05-04T04:26:55.391823Z","shell.execute_reply.started":"2023-05-04T04:26:55.058575Z","shell.execute_reply":"2023-05-04T04:26:55.390837Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"raw_datasets = datasets.DatasetDict({'train_dict': datasets.Dataset.from_dict(train),\n                                    'valid_dict': datasets.Dataset.from_dict(valid),\n                                    'test_dict': datasets.Dataset.from_dict(test)})","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:26:55.393387Z","iopub.execute_input":"2023-05-04T04:26:55.393768Z","iopub.status.idle":"2023-05-04T04:26:55.422233Z","shell.execute_reply.started":"2023-05-04T04:26:55.393729Z","shell.execute_reply":"2023-05-04T04:26:55.421359Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(raw_datasets['train_dict'])\nprint(raw_datasets['valid_dict'])\nprint(raw_datasets['test_dict'])","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:26:55.423565Z","iopub.execute_input":"2023-05-04T04:26:55.424078Z","iopub.status.idle":"2023-05-04T04:26:55.430612Z","shell.execute_reply.started":"2023-05-04T04:26:55.424038Z","shell.execute_reply":"2023-05-04T04:26:55.429467Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['inputs', 'summaries'],\n    num_rows: 1148\n})\nDataset({\n    features: ['inputs', 'summaries'],\n    num_rows: 104\n})\nDataset({\n    features: ['inputs', 'summaries'],\n    num_rows: 101\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Importing PLM, Tokenizer, metric for evaluation**\n* Model: Google:Pegasus-Large (As shown in mandate 2 this model had best performance on dataset before training)\n* Evaluation metrics: Rouge Score","metadata":{}},{"cell_type":"code","source":"model_name = 'google/pegasus-large'\ntokenizer = PegasusTokenizer.from_pretrained(model_name)\nmodel = PegasusForConditionalGeneration.from_pretrained(model_name)\nmetric = datasets.load_metric(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:26:55.432222Z","iopub.execute_input":"2023-05-04T04:26:55.433397Z","iopub.status.idle":"2023-05-04T04:27:32.006967Z","shell.execute_reply.started":"2023-05-04T04:26:55.433359Z","shell.execute_reply":"2023-05-04T04:27:32.005926Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73675d282de84189a30c7335cc050b8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0076c210a2d4bd38dbaf93122d5b03e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"057579071d7349b5a9ee9d10dd62b3cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/3.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde3e292dfe743039bf9796076dd4d21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12bbac7f4cef49448cfe4f862a8a2276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/260 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e36ab723d44909b80c1bc5799824ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f77f874641654320876332dabc6e6d53"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Preprocessing of Data**\n\n* This function tokenizes inputs and summaries using pegasus tokenizer and returns data with labels.\n* max_length: Max number of input tokens of data.\n* We will use this tokenized dataset for training of model.","metadata":{}},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 32\n\ndef preprocess(examples):\n    model_inputs = tokenizer(examples['inputs'], max_length=max_input_length, truncation=True)\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(examples['summaries'], max_length=max_target_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = raw_datasets.map(preprocess, batched=True)\nprint(tokenized_datasets)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:27:32.008198Z","iopub.execute_input":"2023-05-04T04:27:32.009216Z","iopub.status.idle":"2023-05-04T04:27:32.846002Z","shell.execute_reply.started":"2023-05-04T04:27:32.009176Z","shell.execute_reply":"2023-05-04T04:27:32.844942Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf3c29366f74c18bb9ecefdc95ae12b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3587: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be1beed16a844c6c9be143142decd61e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6826cb20e54ff9b3f8122dce5f0651"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train_dict: Dataset({\n        features: ['inputs', 'summaries', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 1148\n    })\n    valid_dict: Dataset({\n        features: ['inputs', 'summaries', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 104\n    })\n    test_dict: Dataset({\n        features: ['inputs', 'summaries', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 101\n    })\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Finetuning of Model**\n\n**Why do we freeze layers?**\nFreezing layers during training prevents its weights from being modified as well as minimises computational time for training the model.\n\nfreeze_params: This function freezez parameters of model.\n\nfreeze_embeds: Used to freeze embed_positions and embed_tokens.\n\nembed_positions: encoding that denotes the position of words.\n\nembed_tokens: the pre-trained embeddings for different words.\n\n","metadata":{}},{"cell_type":"code","source":"def freeze_params(model: nn.Module):\n    for par in model.parameters():\n        par.requires_grad = False\n\ndef freeze_embeds(model):\n    freeze_params(model.model.shared)\n    for d in [model.model.encoder, model.model.decoder]:\n        freeze_params(d.embed_positions)\n        freeze_params(d.embed_tokens)\n\nfreeze_embeds(model)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:27:32.850585Z","iopub.execute_input":"2023-05-04T04:27:32.851584Z","iopub.status.idle":"2023-05-04T04:27:32.858836Z","shell.execute_reply.started":"2023-05-04T04:27:32.851544Z","shell.execute_reply":"2023-05-04T04:27:32.857328Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Arguments for training Model on Dataset**\n\n* Data is trained using initial learning rate of 2e-5 with 5 train epochs.\n* fp16: used 16 bit mixed precision training.\n* optimizer: optimizer with weight decay fixed that can be used to fine-tuned models (used Adafactor)\n* DataCollator: objects that will form a batch by using a list of dataset elements as input.","metadata":{}},{"cell_type":"code","source":"batch_size = 1\nargs = Seq2SeqTrainingArguments(\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=False,\n    output_dir = \"none\"\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\noptimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\nlr_scheduler = AdafactorSchedule(optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:27:32.860339Z","iopub.execute_input":"2023-05-04T04:27:32.860743Z","iopub.status.idle":"2023-05-04T04:27:32.911056Z","shell.execute_reply.started":"2023-05-04T04:27:32.860703Z","shell.execute_reply":"2023-05-04T04:27:32.910083Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Computing evaluation Metrics**\n* This function is used to calculate rouge score of the model for model evaluation.","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n  predictions, labels = eval_pred\n  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n  decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n  decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n  result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n  result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n  result[\"gen_len\"] = np.mean(prediction_lens)\n  \n  return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:27:32.912555Z","iopub.execute_input":"2023-05-04T04:27:32.912922Z","iopub.status.idle":"2023-05-04T04:27:32.921296Z","shell.execute_reply.started":"2023-05-04T04:27:32.912884Z","shell.execute_reply":"2023-05-04T04:27:32.920139Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Training Model on Dataset**\n* train_dataset: tokenized_dataset is given as input for training of model.\n* eval_dataset: tokenized validation dataset","metadata":{}},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train_dict\"],\n    eval_dataset=tokenized_datasets[\"valid_dict\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    optimizers=(optimizer, lr_scheduler),\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:27:32.922550Z","iopub.execute_input":"2023-05-04T04:27:32.923770Z","iopub.status.idle":"2023-05-04T05:34:40.558348Z","shell.execute_reply.started":"2023-05-04T04:27:32.923668Z","shell.execute_reply":"2023-05-04T05:34:40.557411Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230504_043544-ec5p4rht</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/myteam2/huggingface/runs/ec5p4rht' target=\"_blank\">light-cantina-13</a></strong> to <a href='https://wandb.ai/myteam2/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/myteam2/huggingface' target=\"_blank\">https://wandb.ai/myteam2/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/myteam2/huggingface/runs/ec5p4rht' target=\"_blank\">https://wandb.ai/myteam2/huggingface/runs/ec5p4rht</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2870' max='2870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2870/2870 58:17, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.689700</td>\n      <td>0.858080</td>\n      <td>66.932600</td>\n      <td>53.038700</td>\n      <td>63.635200</td>\n      <td>63.407000</td>\n      <td>23.144200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.067000</td>\n      <td>0.975797</td>\n      <td>62.563400</td>\n      <td>50.359500</td>\n      <td>59.806300</td>\n      <td>59.888400</td>\n      <td>24.490400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.751700</td>\n      <td>1.175313</td>\n      <td>35.347500</td>\n      <td>23.727600</td>\n      <td>33.159700</td>\n      <td>33.201400</td>\n      <td>18.701900</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.640900</td>\n      <td>1.262829</td>\n      <td>43.790200</td>\n      <td>31.843400</td>\n      <td>41.334000</td>\n      <td>41.080500</td>\n      <td>37.615400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.584400</td>\n      <td>1.433784</td>\n      <td>25.551400</td>\n      <td>15.267600</td>\n      <td>24.199900</td>\n      <td>24.114100</td>\n      <td>19.240400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2870, training_loss=0.9005455309505662, metrics={'train_runtime': 4022.4049, 'train_samples_per_second': 1.427, 'train_steps_per_second': 0.714, 'total_flos': 658261755346944.0, 'train_loss': 0.9005455309505662, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"**Output Prediction**\n* trainer.predict: gives us output in encoded form\n* tokenizer.decode: decodes the output from encoded form","metadata":{}},{"cell_type":"code","source":"out = trainer.predict(tokenized_datasets[\"test_dict\"])\n\npredicted_summaries = []\nfor i in range(0, 101): \n  predicted_summaries.append(tokenizer.decode(out[0][i], skip_special_tokens =  True))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:34:40.559888Z","iopub.execute_input":"2023-05-04T05:34:40.562463Z","iopub.status.idle":"2023-05-04T05:35:58.399451Z","shell.execute_reply.started":"2023-05-04T05:34:40.562421Z","shell.execute_reply":"2023-05-04T05:35:58.398076Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"markdown","source":"**Rouge Score on test data**","metadata":{}},{"cell_type":"code","source":"out.metrics","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:35:58.401524Z","iopub.execute_input":"2023-05-04T05:35:58.402153Z","iopub.status.idle":"2023-05-04T05:35:58.417166Z","shell.execute_reply.started":"2023-05-04T05:35:58.402112Z","shell.execute_reply":"2023-05-04T05:35:58.415650Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 1.9140664339065552,\n 'test_rouge1': 45.949,\n 'test_rouge2': 28.0132,\n 'test_rougeL': 39.6724,\n 'test_rougeLsum': 39.5181,\n 'test_gen_len': 25.4257,\n 'test_runtime': 76.4796,\n 'test_samples_per_second': 1.321,\n 'test_steps_per_second': 0.667}"},"metadata":{}}]},{"cell_type":"markdown","source":"**Testing model**\nGiving set of tweets as input to trained model","metadata":{}},{"cell_type":"code","source":"input_tweet = [\"Just finished an intense workout session at the gym! Feeling energized and ready to take on the day. 💪 #FitnessGoals #Workout. Remember, fitness is not just about the physical aspect. It's also about mental strength and overall well-being. Take care of your mind and body. #Fitness #Wellness. Finding the motivation to exercise can be tough sometimes, but the feeling you get after a great workout is worth it. Push through and stay committed to your fitness journey. #FitnessMotivation #StayActive\"]\nprint(input_tweet)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T08:56:53.900244Z","iopub.execute_input":"2023-05-04T08:56:53.900659Z","iopub.status.idle":"2023-05-04T08:56:53.907222Z","shell.execute_reply.started":"2023-05-04T08:56:53.900623Z","shell.execute_reply":"2023-05-04T08:56:53.906220Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[\"Just finished an intense workout session at the gym! Feeling energized and ready to take on the day. 💪 #FitnessGoals #Workout. Remember, fitness is not just about the physical aspect. It's also about mental strength and overall well-being. Take care of your mind and body. #Fitness #Wellness. Finding the motivation to exercise can be tough sometimes, but the feeling you get after a great workout is worth it. Push through and stay committed to your fitness journey. #FitnessMotivation #StayActive\"]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Preprocessing given input**","metadata":{}},{"cell_type":"code","source":"input_tweet = pd.DataFrame(input_tweet)\ninput_tweet.columns = ['inputs']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tweet['inputs'][0] = p.clean(input_tweet['inputs'][0])\ninp = datasets.DatasetDict({'input_dict':datasets.Dataset.from_dict(input_tweet)})\ninp","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:35:58.460197Z","iopub.execute_input":"2023-05-04T05:35:58.461092Z","iopub.status.idle":"2023-05-04T05:35:58.484653Z","shell.execute_reply.started":"2023-05-04T05:35:58.461049Z","shell.execute_reply":"2023-05-04T05:35:58.483153Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    input_dict: Dataset({\n        features: ['inputs'],\n        num_rows: 1\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"**Tokenizing input**","metadata":{}},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 32\n\ndef prep(examples):\n    model_inputs = tokenizer(examples['inputs'], max_length=max_input_length, truncation=True)\n    return model_inputs\n\ntokenized_input = inp.map(prep, batched=True)\ntokenized_input","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:35:58.489835Z","iopub.execute_input":"2023-05-04T05:35:58.492861Z","iopub.status.idle":"2023-05-04T05:35:58.552500Z","shell.execute_reply.started":"2023-05-04T05:35:58.492816Z","shell.execute_reply":"2023-05-04T05:35:58.551348Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87314733fa1945cb9d01b2ac2b17196b"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    input_dict: Dataset({\n        features: ['inputs', 'input_ids', 'attention_mask'],\n        num_rows: 1\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"**Generating summary**","metadata":{}},{"cell_type":"code","source":"output = trainer.predict(tokenized_input['input_dict'])\npredicted_summaries = []\nfor i in range(0, 1): \n  predicted_summaries.append(tokenizer.decode(output[0][i], skip_special_tokens =  True))","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:35:58.556092Z","iopub.execute_input":"2023-05-04T05:35:58.556605Z","iopub.status.idle":"2023-05-04T05:35:59.669804Z","shell.execute_reply.started":"2023-05-04T05:35:58.556560Z","shell.execute_reply":"2023-05-04T05:35:59.668648Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"predicted_summaries","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:35:59.673844Z","iopub.execute_input":"2023-05-04T05:35:59.677889Z","iopub.status.idle":"2023-05-04T05:35:59.689129Z","shell.execute_reply.started":"2023-05-04T05:35:59.677842Z","shell.execute_reply":"2023-05-04T05:35:59.686479Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['The author completed a challenging workout at the gym and is experiencing a mix of physical and mental fortitude.']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}